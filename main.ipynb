{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e04475f-5b04-4f44-91e4-00583b958f78",
   "metadata": {},
   "source": [
    "## Import Libraries and Functions and Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a978bf6c-0334-4ae9-8226-21a7b61bef9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"f9c4e79d-2255-4ae2-8922-aba4c0ef202c\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"f9c4e79d-2255-4ae2-8922-aba4c0ef202c\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"f9c4e79d-2255-4ae2-8922-aba4c0ef202c\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Physics Informed Neural Network with Taylor Series\n",
    "\n",
    "from miscFun import *\n",
    "output_notebook()\n",
    "\n",
    "'''\n",
    "N_INPUT: The number of input bio-z dimensions for one heartbeat\n",
    "N_FEAT: The number of physiological features\n",
    "N_EXT: The number of features extracted by the CNN\n",
    "'''\n",
    "#model_DNN 函数定义了三个参数：心跳数据的输入维度数量 N_INPUT，生理特征的数量 N_FEAT，以及CNN提取的特征数量 N_EXT。\n",
    "def model_DNN(N_INPUT, N_FEAT=1, N_EXT=100):\n",
    "    # The input to the model is a 1D tensor representing a time series of heartbeat data, sampled with 250/8 points for 30 seconds \n",
    "    inp_beat=tf.keras.Input(shape=(N_INPUT))\n",
    "    \n",
    "    # Define the 1D CNN for NN feature extraction\n",
    "    # The input tensor is first expanded by one dimension (from 1D to 2D) to be compatible with the Conv1D layer\n",
    "    cnn1_1 = tf.keras.layers.Conv1D(32,5,activation='relu')(tf.keras.backend.expand_dims(inp_beat,axis=-1))\n",
    "    #tf.keras.layers.Conv1D(32, 5, activation='relu') 创建了一个一维卷积层，\n",
    "    #其中：32 表示卷积层中滤波器的数量。5 是每个滤波器的尺寸，即卷积窗口的大小。activation='relu' 指定了激活函数为ReLU\n",
    "    cnn1_2 = tf.keras.layers.Conv1D(64,3,activation='relu')(cnn1_1)\n",
    "    #创建了第二个一维卷积层，与第一个卷积层类似，但滤波器数量增加到64，卷积窗口大小变为3。这允许网络在更细粒度上学习特征。\n",
    "    mp_cnn1 = tf.keras.layers.MaxPooling1D(pool_size=3,strides=1)(cnn1_2)\n",
    "    #创建了一个一维最大池化层，指定了池化窗口的大小为3，池化窗口移动的步长为1，这意味着池化操作将应用于每个可能的位置，以减少特征的空间维度，同时保留尽可能多的信息。\n",
    "    fl_cnn1 = tf.keras.layers.Flatten()(mp_cnn1)\n",
    "    #将经过卷积和池化操作后的二维张量展平为一维张量。这是为了准备将特征输入到后续的全连接层中进行进一步的处理。\n",
    "    \n",
    "    # A fully connected layer further processes the flattened tensor and extracts N_EXT features\n",
    "    # 创建了一个全连接层，该层输出的节点数为N_EXT个，指定了使用ReLU激活函数，是将前一层的输出（fl_cnn）作为当前全连接层的输入\n",
    "    feat_ext = tf.keras.layers.Dense(N_EXT,activation='relu')(fl_cnn1) \n",
    "    \n",
    "    # Define physiological features (case study uses 3 features), each of these features is expected to be a 1D tensor\n",
    "    # 这行注释说明了接下来的代码将定义三个生理特征输入，案例研究中使用了三个特征。\n",
    "    inp_feat1 = tf.keras.Input(shape=(N_FEAT)) # feat 1 创建了一个输入层，用于接收第一个生理特征, shape=(N_FEAT) 指定了输入数据的形状\n",
    "    inp_feat2 = tf.keras.Input(shape=(N_FEAT)) # feat 2\n",
    "    inp_feat3 = tf.keras.Input(shape=(N_FEAT)) # feat 3\n",
    "    \n",
    "    # The extracted features and physiological features are concatenated together \n",
    "    #创建了一个拼接层，用于沿着指定的轴将多个输入张量拼接在一起。\n",
    "    #这里包含了三个生理特征的输入层 inp_feat1、inp_feat2 和 inp_feat3，以及之前通过全连接层 feat_ext 提取的特征。这些输入被作为一个列表传递给 Concatenate 层。\n",
    "    #feat_comb 包含了所有拼接在一起的特征，它将作为模型中下一个层的输入\n",
    "    feat_comb = tf.keras.layers.Concatenate()([inp_feat1,inp_feat2,inp_feat3,feat_ext])\n",
    "    \n",
    "    # A fully connected layer with is applied to the concatenated features\n",
    "    #全连接层 dense1_1，该层有60个节点，使用ReLU激活函数\n",
    "    dense1_1 = tf.keras.layers.Dense(60,activation='relu')(feat_comb) \n",
    "    #输出层 out，N_FEAT 是输出层的节点数，与函数 model_DNN 的参数相对应，表示模型最终预测的生理特征的数量，dense1_1的输出作为输入\n",
    "    out = tf.keras.layers.Dense(N_FEAT)(dense1_1) \n",
    "    \n",
    "    # Finally, the model is instantiated with the specified inputs and outputs\n",
    "    #创建了一个新的模型实例\n",
    "    model = tf.keras.Model(inputs=[inp_beat, inp_feat1, inp_feat2, inp_feat3], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3147e93-a796-4077-b31c-248be2d20914",
   "metadata": {},
   "source": [
    "### Import a Demo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "199f70e4-06d2-4848-9ae3-57deed7785bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   trial_id                                         bioz_beats  phys_feat_1  \\\n",
      "0         1  [4.674306050529548e-06, 3.873631220239295e-06,...     5.817552   \n",
      "1         1  [4.806376660377724e-06, 4.00727594328936e-06, ...     6.002678   \n",
      "2         1  [4.4183450820834e-06, 3.6333050096782107e-06, ...     5.632601   \n",
      "3         1  [4.076650431880851e-06, 3.4283849875982737e-06...     5.119284   \n",
      "4         1  [3.848732650901477e-06, 3.1940944086055694e-06...     4.833644   \n",
      "\n",
      "   phys_feat_2  phys_feat_3         sys  \n",
      "0   905.797101    97.832540  141.154438  \n",
      "1   905.923964    99.785117  143.502124  \n",
      "2   897.170462   100.450450  147.810844  \n",
      "3   919.250190   102.752581  150.845861  \n",
      "4   914.810008   102.519611  153.840739  \n"
     ]
    }
   ],
   "source": [
    "# load an example data for demo\n",
    "# pd.read_pickle：这是Pandas库提供的函数，用于读取pickle格式的文件\n",
    "# compression='gzip'：这个参数指定了文件压缩的类型。告诉 read_pickle 函数使用gzip压缩算法来解压缩pickle文件\n",
    "df_demo_data = pd.read_pickle('data_demo_pinn_bioz_bp',compression='gzip')\n",
    "print(df_demo_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40a95ce-5e05-4499-a4da-27394b896c3f",
   "metadata": {},
   "source": [
    "### Preprocess and Prepare the Train/Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb49b2b3-be56-4654-b4ec-0134c8486bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标准化后的心跳数据前5行:\n",
      "0    [2.9279891461837044, 2.4172478429202755, 0.969...\n",
      "1    [3.012235475460972, 2.5024982809790393, 1.0585...\n",
      "2    [2.764714576204573, 2.2639465059145487, 0.8654...\n",
      "3    [2.5467514726318945, 2.1332303709962863, 0.887...\n",
      "4    [2.401365330729425, 1.9837790942355338, 0.7758...\n",
      "Name: bioz_beats_scaled, dtype: object\n",
      "\n",
      "标准化后的目标变量前5行:\n",
      "0   -0.952151\n",
      "1   -0.812206\n",
      "2   -0.555365\n",
      "3   -0.374448\n",
      "4   -0.195925\n",
      "Name: sys_scaled, dtype: float64\n",
      "\n",
      "标准化后的生理特征前5行:\n",
      "phys_feat_1_scaled: \n",
      "0      [1.048386639332269]\n",
      "1     [1.1888416577787004]\n",
      "2     [0.9080649136981447]\n",
      "3     [0.5186121459215011]\n",
      "4    [0.30189754244438355]\n",
      "Name: phys_feat_1_scaled, dtype: object\n",
      "\n",
      "phys_feat_2_scaled: \n",
      "0    [-0.09849125703922874]\n",
      "1    [-0.09499063973369752]\n",
      "2    [-0.33653323381721845]\n",
      "3     [0.27273092140839417]\n",
      "4     [0.15020931571389476]\n",
      "Name: phys_feat_2_scaled, dtype: object\n",
      "\n",
      "phys_feat_3_scaled: \n",
      "0     [1.145099680369798]\n",
      "1     [1.476112018152463]\n",
      "2     [1.588903218155048]\n",
      "3    [1.9791739417836047]\n",
      "4     [1.939679518748165]\n",
      "Name: phys_feat_3_scaled, dtype: object\n",
      "\n",
      "训练集的形状: (65, 34)\n",
      "测试集的形状: (813, 34)\n",
      "训练集中的心跳数据前5行:\n",
      "[[ 1.40342188e+00  1.20696073e+00  5.71062553e-01 -3.56578657e-01\n",
      "  -1.12391665e+00 -1.37596205e+00 -1.14565952e+00 -7.14439229e-01\n",
      "  -3.39763334e-01 -1.41029856e-01 -1.31680954e-01 -2.57357241e-01\n",
      "  -3.99481482e-01 -4.20102169e-01 -2.54657010e-01  4.96067092e-02\n",
      "   3.84484809e-01  6.66217117e-01  8.77615530e-01  1.04565355e+00\n",
      "   1.19983055e+00  1.33863092e+00  3.64870325e-01  4.15806730e-01\n",
      "  -5.36971437e-02 -5.36971437e-02 -5.36971437e-02 -5.36971437e-02\n",
      "  -5.36971437e-02 -5.36971437e-02 -5.36971437e-02 -5.36971437e-02\n",
      "  -5.36971437e-02 -5.36971437e-02]\n",
      " [ 2.90389556e+00  2.43448161e+00  1.07607542e+00 -7.75745576e-01\n",
      "  -2.33136327e+00 -3.04604945e+00 -2.90130425e+00 -2.21531077e+00\n",
      "  -1.38535853e+00 -7.50843796e-01 -5.04417660e-01 -6.00278501e-01\n",
      "  -7.81600968e-01 -7.77920340e-01 -4.83809021e-01  3.65099885e-02\n",
      "   6.63368237e-01  1.32168704e+00  1.98257189e+00  2.56547973e+00\n",
      "   8.70011771e-01 -5.36971437e-02 -5.36971437e-02 -5.36971437e-02\n",
      "  -5.36971437e-02 -5.36971437e-02 -5.36971437e-02 -5.36971437e-02\n",
      "  -5.36971437e-02 -5.36971437e-02 -5.36971437e-02 -5.36971437e-02\n",
      "  -5.36971437e-02 -5.36971437e-02]\n",
      " [ 1.69307606e+00  1.51099574e+00  8.68404099e-01 -1.64179775e-01\n",
      "  -1.15624948e+00 -1.66559626e+00 -1.63324588e+00 -1.29902554e+00\n",
      "  -8.82153766e-01 -4.75997973e-01 -1.57020558e-01 -2.59073591e-02\n",
      "  -8.95675991e-02 -1.91880604e-01 -1.39758980e-01  1.22833679e-01\n",
      "   5.00711645e-01  8.65374225e-01  1.15824342e+00  1.39527963e+00\n",
      "   1.57939033e+00 -5.36971437e-02 -5.36971437e-02 -5.36971437e-02\n",
      "  -5.36971437e-02 -5.36971437e-02 -5.36971437e-02 -5.36971437e-02\n",
      "  -5.36971437e-02 -5.36971437e-02 -5.36971437e-02 -5.36971437e-02\n",
      "  -5.36971437e-02 -5.36971437e-02]\n",
      " [ 1.51470041e+00  1.31336620e+00  6.91663890e-01 -2.30935577e-01\n",
      "  -1.07302187e+00 -1.51237499e+00 -1.53305151e+00 -1.29795924e+00\n",
      "  -9.45252044e-01 -5.60697027e-01 -2.38626662e-01 -5.90187682e-02\n",
      "  -1.10749904e-02  1.16057078e-03  6.63813331e-02  2.05023462e-01\n",
      "   3.90152431e-01  5.98973185e-01  8.21930263e-01  5.60783583e-01\n",
      "   4.10310785e-01 -5.36971437e-02 -5.36971437e-02 -5.36971437e-02\n",
      "  -5.36971437e-02 -5.36971437e-02 -5.36971437e-02 -5.36971437e-02\n",
      "  -5.36971437e-02 -5.36971437e-02 -5.36971437e-02 -5.36971437e-02\n",
      "  -5.36971437e-02 -5.36971437e-02]\n",
      " [ 1.15089636e+00  1.03027617e+00  6.13010659e-01 -6.81283757e-02\n",
      "  -7.42857247e-01 -1.11156968e+00 -1.11424677e+00 -9.17734196e-01\n",
      "  -7.16759169e-01 -6.11554356e-01 -6.11253383e-01 -6.71860400e-01\n",
      "  -7.25346017e-01 -7.04531553e-01 -5.69433216e-01 -3.27278593e-01\n",
      "  -3.01530721e-02  2.55265767e-01  4.87385419e-01  6.69422653e-01\n",
      "   8.34778625e-01  1.00553224e+00  1.15602026e+00 -5.36971437e-02\n",
      "  -5.36971437e-02 -5.36971437e-02 -5.36971437e-02 -5.36971437e-02\n",
      "  -5.36971437e-02 -5.36971437e-02 -5.36971437e-02 -5.36971437e-02\n",
      "  -5.36971437e-02 -5.36971437e-02]]\n",
      "\n",
      "测试集中的心跳数据前5行:\n",
      "[[ 2.54675147  2.13323037  0.88702173 -0.79174565 -2.15916092 -2.69247221\n",
      "  -2.36281985 -1.5007918  -0.56448789  0.04059304  0.14182518 -0.10710032\n",
      "  -0.37117639 -0.38507526 -0.0688361   0.51529815  1.23916272  1.92762669\n",
      "   2.33367642 -0.05369714 -0.05369714 -0.05369714 -0.05369714 -0.05369714\n",
      "  -0.05369714 -0.05369714 -0.05369714 -0.05369714 -0.05369714 -0.05369714\n",
      "  -0.05369714 -0.05369714 -0.05369714 -0.05369714]\n",
      " [ 2.40136533  1.98377909  0.77580667 -0.82450105 -2.09651659 -2.54509396\n",
      "  -2.15905673 -1.28364438 -0.38100423  0.17709246  0.2580906   0.01502885\n",
      "  -0.24286887 -0.26439284  0.02861304  0.57443956  1.25340725  1.91054314\n",
      "   2.31900819 -0.05369714 -0.05369714 -0.05369714 -0.05369714 -0.05369714\n",
      "  -0.05369714 -0.05369714 -0.05369714 -0.05369714 -0.05369714 -0.05369714\n",
      "  -0.05369714 -0.05369714 -0.05369714 -0.05369714]\n",
      " [ 2.4549589   2.00556206  0.74920088 -0.89225766 -2.15562954 -2.54770623\n",
      "  -2.10716603 -1.21594408 -0.33065582  0.21799964  0.31790869  0.10074727\n",
      "  -0.14516102 -0.17426198  0.08829989  0.57930652  1.19579638  1.83262201\n",
      "   2.31643895 -0.05369714 -0.05369714 -0.05369714 -0.05369714 -0.05369714\n",
      "  -0.05369714 -0.05369714 -0.05369714 -0.05369714 -0.05369714 -0.05369714\n",
      "  -0.05369714 -0.05369714 -0.05369714 -0.05369714]\n",
      " [ 2.42477464  1.98875603  0.74565951 -0.88945542 -2.14097652 -2.49516178\n",
      "  -1.98969719 -1.02561944 -0.07846929  0.49031113  0.54962054  0.25541303\n",
      "  -0.05675755 -0.11266678  0.1569712   0.66845757  1.30545724  1.9481424\n",
      "   2.39030233 -0.05369714 -0.05369714 -0.05369714 -0.05369714 -0.05369714\n",
      "  -0.05369714 -0.05369714 -0.05369714 -0.05369714 -0.05369714 -0.05369714\n",
      "  -0.05369714 -0.05369714 -0.05369714 -0.05369714]\n",
      " [ 2.47566375  2.01679442  0.71557145 -0.96076847 -2.20359031 -2.51936707\n",
      "  -1.97694078 -0.98228626 -0.00717429  0.57615583  0.62559402  0.30083236\n",
      "  -0.04723178 -0.12593567  0.14608205  0.69120624  1.38993798  2.08719733\n",
      "   2.50210313 -0.05369714 -0.05369714 -0.05369714 -0.05369714 -0.05369714\n",
      "  -0.05369714 -0.05369714 -0.05369714 -0.05369714 -0.05369714 -0.05369714\n",
      "  -0.05369714 -0.05369714 -0.05369714 -0.05369714]]\n",
      "\n",
      "训练集中的特征数据前5行:\n",
      "[[array([-0.99500316])]\n",
      " [array([1.60465036])]\n",
      " [array([-0.4584487])]\n",
      " [array([-0.7303574])]\n",
      " [array([-1.40270978])]]\n",
      "\n",
      "训练集中的目标变量前5行:\n",
      "[[ 0.78937263]\n",
      " [-0.87963501]\n",
      " [ 1.32824726]\n",
      " [ 1.44055458]\n",
      " [ 2.33066091]]\n",
      "\n",
      "测试集中的特征数据前5行:\n",
      "[[array([0.51861215])]\n",
      " [array([0.30189754])]\n",
      " [array([0.35020737])]\n",
      " [array([0.30136417])]\n",
      " [array([0.37178794])]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize a SEED value to ensure that the random processes in the code can be reproduced.\n",
    "SEED = 123\n",
    "\n",
    "# Call the function with seed value\n",
    "set_global_determinism(seed=SEED)\n",
    "\n",
    "# The keys for the beat data (beat_key), the target (out_key), and the features (feat_keys) are defined\n",
    "beat_key = 'bioz_beats'\n",
    "out_key = 'sys'\n",
    "feat_keys = ['phys_feat_1','phys_feat_2','phys_feat_3']\n",
    "\n",
    "# Data scaling of BP, input beats, and input features\n",
    "# This scaler standardizes by removing the mean and scaling to unit variance\n",
    "# This is done to ensure having the same scale, which can improve the performance of machine learning algorithms\n",
    "# preprocessing.StandardScaler 是Scikit-learn库中用于数据标准化的类。Standardization。\n",
    "# to_numpy() 方法将Pandas Series转换为NumPy数组，[:, None] 确保数据是二维数组的形式，即使只有一列数据。\n",
    "scaler_out = preprocessing.StandardScaler().fit(df_demo_data[out_key].to_numpy()[:, None]) \n",
    "# 标准化心跳数据\n",
    "scaler_beats = preprocessing.StandardScaler().fit(np.concatenate(df_demo_data[beat_key].to_numpy())[:, None])\n",
    "# 标准化特征数据\n",
    "scaler_X = [preprocessing.StandardScaler().fit(df_demo_data[a].to_numpy()[:, None]) for a in feat_keys]\n",
    "\n",
    "# Apply Scaling\n",
    "# The scaled versions of the BP, input beats, and input features are then added to the dataframe\n",
    "df_demo_data.loc[df_demo_data.index,beat_key+'_scaled'] = df_demo_data.apply(lambda x: np.concatenate(scaler_beats.transform(x[beat_key][:, None])), axis=1).to_numpy()   \n",
    "df_demo_data.loc[df_demo_data.index,out_key+'_scaled'] = df_demo_data.apply(lambda x: np.concatenate(scaler_out.transform(np.array([x[out_key]])[:, None]))[0], axis=1).to_numpy()\n",
    "for tmp_key, tmp_count in zip(feat_keys, range(len(feat_keys))):\n",
    "    df_demo_data.loc[df_demo_data.index, tmp_key+'_scaled'] = df_demo_data.apply(lambda x: np.concatenate(scaler_X[tmp_count].transform(np.array([x[tmp_key]])[:, None])), axis=1).to_numpy()\n",
    "\n",
    "# Fetch scaled feature names\n",
    "X_keys = [a+'_scaled' for a in feat_keys]\n",
    "\n",
    "# 查看标准化后的心跳数据的前5行\n",
    "print(\"标准化后的心跳数据前5行:\")\n",
    "print(df_demo_data[beat_key + '_scaled'].head())\n",
    "\n",
    "# 查看标准化后的目标变量的前5行\n",
    "print(\"\\n标准化后的目标变量前5行:\")\n",
    "print(df_demo_data[out_key + '_scaled'].head())\n",
    "\n",
    "# 查看所有标准化后的生理特征的前5行\n",
    "print(\"\\n标准化后的生理特征前5行:\")\n",
    "for key in X_keys:  # X_keys 包含了所有标准化特征的键名\n",
    "    print(f\"{key}: \")\n",
    "    print(df_demo_data[key].head())\n",
    "    print()\n",
    "\n",
    "# Prepare train/test using minimal training the BP\n",
    "# Fetch data shapes\n",
    "# 获取序列数据的长度\n",
    "length_seq_x = df_demo_data.apply(lambda x: len(x[beat_key+'_scaled']), axis=1).unique()[0]\n",
    "# Set the length of the target to 1\n",
    "# 设置了目标变量（血压 BP）的长度为1。这通常意味着每个心跳序列对应的是一个单独的血压值，或者模型的输出是一个标量值。\n",
    "length_seq_y = 1\n",
    "\n",
    "# Start with all points\n",
    "# Reshape the scaled beat data into a 2D array where each row corresponds to a sample and each column corresponds to a time point in the beat sequence\n",
    "# The same is done for the features and the target\n",
    "# 这行代码首先使用 np.concatenate 将DataFrame中所有行的标准化心跳数据（beat_key+'_scaled'）合并成一个一维数组。然后，使用 np.reshape 将这个一维数组重塑为一个二维数组\n",
    "all_beats = np.reshape(np.concatenate(df_demo_data[beat_key+'_scaled'].values), (len(df_demo_data), length_seq_x))\n",
    "# 将所有生理特征的标准化数据合并成一个二维数组\n",
    "[all_feat1, all_feat2, all_feat3] = [df_demo_data[a].values[:, None] for a in X_keys]\n",
    "# 将所有目标变量的标准化数据合并成一个二维数组\n",
    "all_out = df_demo_data[out_key+'_scaled'].values[:, None]\n",
    "\n",
    "# Used only for plotting purposes\n",
    "# 计算标准化后的目标变量的最大值和最小值\n",
    "#out_max_rescaled = np.concatenate(scaler_out.inverse_transform(all_out[:, 0][:, None])).max()\n",
    "#out_min_rescaled = np.concatenate(scaler_out.inverse_transform(all_out[:, 0][:, None])).min()\n",
    "\n",
    "# 逆转换 all_out 以获取原始尺度的值\n",
    "original_out = scaler_out.inverse_transform(all_out)\n",
    "\n",
    "# 计算逆转换后数组的最大值和最小值\n",
    "out_max_rescaled = original_out.max()\n",
    "out_min_rescaled = original_out.min()\n",
    "\n",
    "# Given different trials have time gaps, ignore first 3 instances from indices to prevent discontiunity in training\n",
    "# 为了避免训练数据中的不连续性，忽略了每个试验的前三个数据点\n",
    "list_all_length = [0]\n",
    "for _, df_tmp in df_demo_data.groupby(['trial_id']):\n",
    "    list_all_length.append(len(df_tmp))\n",
    "ix_ignore_all = np.concatenate(np.array([np.arange(a, a+3,1) for a in list(np.cumsum(list_all_length)[:-1])]))\n",
    "\n",
    "# Update the final indices set\n",
    "# 将所有数据点的索引分为训练集和测试集\n",
    "ix_all=list(set(np.arange(len(df_demo_data)))-set(ix_ignore_all))\n",
    "\n",
    "# Separate train/test based on minimal training criterion\n",
    "# 使用随机种子将数据集分为训练集和测试集，这行代码设置了随机数生成器的种子，以确保数据集的划分是可重复的\n",
    "random.seed(0)\n",
    "bp_dist = df_demo_data[out_key].values\n",
    "\n",
    "# Find indices for train and test datasets\n",
    "# The target values are sorted in ascending order, and the sorted indices are split into multiple subsets\n",
    "# For each subset, a random index is selected as a training index\n",
    "# np.argsort(bp_dist) 根据目标变量 bp_dist（即 df_demo_data[out_key].values）的值进行排序，并返回排序后的索引数组。\n",
    "# np.split 将排序后的索引数组分割为多个子数组，每个子数组的长度由 np.histogram 函数计算得到。\n",
    "ix_split = np.split([a for a in np.argsort(bp_dist) if a not in set(ix_ignore_all)], np.cumsum(np.histogram(bp_dist[ix_all],bins=np.arange(bp_dist[ix_all].min(), bp_dist[ix_all].max(), 1))[0]))\n",
    "# 从每个子数组中随机选择一个索引作为训练集的索引，如果子数组为空，则选择-1作为索引，表示没有数据点被选择\n",
    "ix_train = [random.Random(4).choice(a) if len(a)>0 else -1 for a in ix_split]\n",
    "ix_train = list(set(ix_train)-set([-1]))\n",
    "\n",
    "# Test set is all remaining points not used for training\n",
    "# 将所有数据点的索引分为训练集和测试集\n",
    "ix_test = list(set(ix_all) - set(ix_train))\n",
    "\n",
    "# Build train and test datasets based on the indices\n",
    "# 使用索引将数据集分为训练集和测试集\n",
    "train_beats = all_beats[ix_train, :]\n",
    "test_beats = all_beats[ix_test, :]\n",
    "[train_feat1, train_feat2, train_feat3] = [all_feat1[ix_train, :], all_feat2[ix_train, :], all_feat3[ix_train, :]]\n",
    "[test_feat1, test_feat2, test_feat3] = [all_feat1[ix_test, :], all_feat2[ix_test, :], all_feat3[ix_test, :]]\n",
    "train_out = all_out[ix_train, :]\n",
    "test_out = all_out[ix_test, :]\n",
    "\n",
    "# 查看训练集和测试集的形状\n",
    "print(f\"训练集的形状: {train_beats.shape}\")\n",
    "print(f\"测试集的形状: {test_beats.shape}\")\n",
    "\n",
    "# 输出训练集中的心跳数据的前5行\n",
    "print(\"训练集中的心跳数据前5行:\")\n",
    "print(train_beats[:5])\n",
    "\n",
    "# 输出测试集中的心跳数据的前5行\n",
    "print(\"\\n测试集中的心跳数据前5行:\")\n",
    "print(test_beats[:5])\n",
    "\n",
    "# 输出训练集中的特征数据的前5行\n",
    "print(\"\\n训练集中的特征数据前5行:\")\n",
    "print(train_feat1[:5])\n",
    "\n",
    "# 输出训练集中的目标变量的前5行\n",
    "print(\"\\n训练集中的目标变量前5行:\")\n",
    "print(train_out[:5])\n",
    "\n",
    "# 输出测试集中的特征数据的前5行\n",
    "print(\"\\n测试集中的特征数据前5行:\")\n",
    "print(test_feat1[:5])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab85496f-ad0e-4413-8ad5-9c84f38ba47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 10:58:06.706915: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2024-06-13 10:58:06.706961: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2024-06-13 10:58:06.706971: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2024-06-13 10:58:06.707034: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-06-13 10:58:06.707071: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "#### Define model input tensors\n",
    "# The training, testing, and all data are converted to TensorFlow tensors\n",
    "# The tensors for the different datasets are grouped into lists \n",
    "\n",
    "model_inp = tf.convert_to_tensor(train_beats, dtype=tf.float32)\n",
    "feat1_inp = tf.convert_to_tensor(train_feat1, dtype=tf.float32)\n",
    "feat2_inp = tf.convert_to_tensor(train_feat2, dtype=tf.float32)\n",
    "feat3_inp = tf.convert_to_tensor(train_feat3, dtype=tf.float32)\n",
    "inp_comb = [model_inp, feat1_inp, feat2_inp, feat3_inp]\n",
    "\n",
    "model_inp_test = tf.convert_to_tensor(test_beats, dtype=tf.float32)\n",
    "feat1_inp_test = tf.convert_to_tensor(test_feat1, dtype=tf.float32)\n",
    "feat2_inp_test = tf.convert_to_tensor(test_feat2, dtype=tf.float32)\n",
    "feat3_inp_test = tf.convert_to_tensor(test_feat3, dtype=tf.float32)\n",
    "inp_comb_test = [model_inp_test, feat1_inp_test, feat2_inp_test, feat3_inp_test]\n",
    "\n",
    "model_inp_all = tf.convert_to_tensor(all_beats, dtype=tf.float32)\n",
    "feat1_inp_all = tf.convert_to_tensor(all_feat1, dtype=tf.float32)\n",
    "feat2_inp_all = tf.convert_to_tensor(all_feat2, dtype=tf.float32)\n",
    "feat3_inp_all = tf.convert_to_tensor(all_feat3, dtype=tf.float32)\n",
    "inp_comb_all = [model_inp_all, feat1_inp_all, feat2_inp_all, feat3_inp_all]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e868349-c5ed-4c6c-9b2a-666e84cd1439",
   "metadata": {},
   "source": [
    "### Train the Conventional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7543d519-1fd8-47c3-bee8-2fd9d2afe632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conventional model training Completed. Epoch 342/5000 -- loss: 0.0099\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "###### Conventional model\n",
    "#############################\n",
    "\n",
    "# A Deep Neural Network model is initialized with the dimension of the beats, the diemnsion of each feature, and the number of neurons in the first dense layer\n",
    "model_dnn_conv = model_DNN(np.shape(train_beats)[-1], 1, 64)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-4)\n",
    "\n",
    "# Two lists are initialized to keep track of the training and testing loss during each epoch\n",
    "loss_list_conv = []\n",
    "test_loss_list_conv = []\n",
    "\n",
    "epochs = 5000\n",
    "for epoch in range(epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        tape.watch(inp_comb)      \n",
    "        # Traditional out\n",
    "        yh = model_dnn_conv(inp_comb, training=True)\n",
    "        loss_ini = yh - train_out\n",
    "        loss = K.mean(K.square(loss_ini))\n",
    "        \n",
    "    grads = tape.gradient(loss, model_dnn_conv.trainable_weights)\n",
    "\n",
    "    loss_list_conv.append(float(loss))\n",
    "    loss_final = np.min(loss_list_conv)\n",
    "    optimizer.apply_gradients(zip(grads, model_dnn_conv.trainable_weights))\n",
    "\n",
    "    pred_out = model_dnn_conv(inp_comb_test)\n",
    "    \n",
    "    test_loss_ini = pred_out - test_out\n",
    "    test_loss = K.mean(K.square(test_loss_ini))\n",
    "    test_loss_list_conv.append(float(test_loss))\n",
    "    \n",
    "    # If the training loss reaches a minimum value of 0.01, or the maximum number of epochs is reached, the training process is stopped\n",
    "    if (loss_final<=0.01) | (epoch==epochs-1):\n",
    "        print(\"Conventional model training Completed. Epoch %d/%d -- loss: %.4f\" % (epoch, epochs, float(loss)))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c83887-d459-4504-9904-146bac14cfb3",
   "metadata": {},
   "source": [
    "### Train the PINN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f99ed78b-d46e-4fa8-b1a0-8799d4f5eed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PINN model training Completed. Epoch 2124/5000 -- loss: 0.0099\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "############### PINN MODEL\n",
    "#############################\n",
    "\n",
    "# A Deep Neural Network model is initialized with the dimension of the beats, the diemnsion of each feature, and the number of neurons in the first dense layer\n",
    "model_dnn_pinn = model_DNN(np.shape(train_beats)[-1], 1, 64)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=10e-4)\n",
    "\n",
    "# Two lists are initialized to keep track of the training and testing loss during each epoch\n",
    "loss_list_pinn = []\n",
    "test_loss_list_pinn = []\n",
    "\n",
    "epochs = 5000\n",
    "for epoch in range(epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        tape.watch(inp_comb)      \n",
    "        # Traditional out\n",
    "        yh = model_dnn_pinn(inp_comb, training=True)\n",
    "        loss_ini = yh - train_out\n",
    "        loss = K.mean(K.square(loss_ini))        \n",
    "        \n",
    "        # Additional tf.GradientTape contexts are used to compute the derivatives of the model's predictions with respect to the features \n",
    "        with tf.GradientTape() as deriv_f1:\n",
    "            deriv_f1.watch(inp_comb_all)\n",
    "            yhp = model_dnn_pinn(inp_comb_all, training=True)\n",
    "        dx_f1 = deriv_f1.gradient(yhp, feat1_inp_all)\n",
    "\n",
    "        with tf.GradientTape() as deriv_f2:\n",
    "            deriv_f2.watch(inp_comb_all)\n",
    "            yhp = model_dnn_pinn(inp_comb_all, training=True)\n",
    "        dx_f2 = deriv_f2.gradient(yhp, feat2_inp_all)\n",
    "\n",
    "        with tf.GradientTape() as deriv_f3:\n",
    "            deriv_f3.watch(inp_comb_all)\n",
    "            yhp = model_dnn_pinn(inp_comb_all, training=True)\n",
    "        dx_f3 = deriv_f3.gradient(yhp, feat3_inp_all)\n",
    "\n",
    "        # A physics-based prediction is computed by adding the model's predictions to the product of the computed derivatives and\n",
    "        # the differences in the feature values between consecutive timesteps\n",
    "        pred_physics = (yhp[:-1, 0]\n",
    "                        +Multiply()([dx_f1[:-1, 0], feat1_inp_all[1:, 0] - feat1_inp_all[:-1, 0]])\n",
    "                        +Multiply()([dx_f2[:-1, 0], feat2_inp_all[1:, 0] - feat2_inp_all[:-1, 0]])\n",
    "                        +Multiply()([dx_f3[:-1, 0], feat3_inp_all[1:, 0] - feat3_inp_all[:-1, 0]])\n",
    "                        )\n",
    "\n",
    "        physics_loss_ini = pred_physics - yhp[1:, 0]\n",
    "        physics_loss = K.mean(K.square(tf.gather_nd(physics_loss_ini,indices = np.array(ix_all[:-1])[:, None])))\n",
    "    \n",
    "        # The total loss is computed as the sum of the initial loss and ten times the physics-based loss\n",
    "        # The physics-based loss is multiplied by a factor of ten to emphasize its importance in the loss function\n",
    "        loss_total = loss + physics_loss * 10\n",
    "\n",
    "    grads = tape.gradient(loss_total, model_dnn_pinn.trainable_weights)\n",
    "\n",
    "    loss_list_pinn.append(float(loss))\n",
    "    loss_final=np.min(loss_list_pinn)\n",
    "    optimizer.apply_gradients(zip(grads, model_dnn_pinn.trainable_weights))\n",
    "    \n",
    "    pred_out = model_dnn_pinn(inp_comb_test)\n",
    "    test_loss_ini = pred_out - test_out\n",
    "    test_loss = K.mean(K.square(test_loss_ini))\n",
    "    test_loss_list_pinn.append(float(test_loss))\n",
    "    \n",
    "    # If the training loss reaches a minimum value of 0.01, or the maximum number of epochs is reached, the training process is stopped\n",
    "    if (loss_final<=0.01) | (epoch==epochs-1):\n",
    "        print(\"PINN model training Completed. Epoch %d/%d -- loss: %.4f\" % (epoch,epochs,float(loss)))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7776218f-592d-4278-9ed6-da9326f2fd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Conventional Performance ####\n",
      "Corr: 0.86,  RMSE: 10.2\n",
      "----------------------------------\n",
      "#### PINN Performance ####\n",
      "Corr: 0.95,  RMSE: 5.3\n"
     ]
    }
   ],
   "source": [
    "#The trained model's predictions on the test dataset are computed\n",
    "pred_out = model_dnn_conv(inp_comb_test)\n",
    "\n",
    "#The Pearson correlation coefficient and the Root Mean Square Error are calculated between the actual and predicted test outcomes\n",
    "corr_conv = np.corrcoef(np.concatenate(test_out)[:], np.concatenate(pred_out)[:])[0][1]\n",
    "rmse_conv = np.sqrt(np.mean(np.square\n",
    "                           (np.concatenate(scaler_out.inverse_transform(np.concatenate(test_out)[:][:, None]))-\n",
    "                            np.concatenate(scaler_out.inverse_transform(np.concatenate(pred_out)[:][:, None])))))\n",
    "\n",
    "pred_out = model_dnn_pinn(inp_comb_test)\n",
    "corr_pinn = np.corrcoef(np.concatenate(test_out)[:], np.concatenate(pred_out)[:])[0][1]\n",
    "rmse_pinn = np.sqrt(np.mean(np.square(\n",
    "    np.concatenate(scaler_out.inverse_transform(np.concatenate(test_out)[:][:, None]))-\n",
    "    np.concatenate(scaler_out.inverse_transform(np.concatenate(pred_out)[:][:, None])))))\n",
    "\n",
    "print('#### Conventional Performance ####')\n",
    "print('Corr: %.2f,  RMSE: %.1f'%(corr_conv, rmse_conv))\n",
    "print('----------------------------------')\n",
    "print('#### PINN Performance ####')\n",
    "print('Corr: %.2f,  RMSE: %.1f'%(corr_pinn, rmse_pinn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf77d2b1-8f28-4d2c-a5e9-367dac4dc509",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 343), ('y', 2125)\n",
      "BokehUserWarning: ColumnDataSource's columns must be of the same length. Current lengths: ('x', 343), ('y', 2125)\n"
     ]
    },
    {
     "ename": "SerializationError",
     "evalue": "can't serialize <class 'range'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSerializationError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m figure_settings(s)\n\u001b[1;32m     28\u001b[0m figure_settings(s2)\n\u001b[0;32m---> 30\u001b[0m \u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43ms2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/io/showing.py:149\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(obj, browser, new, notebook_handle, notebook_url, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m state \u001b[38;5;241m=\u001b[39m curstate()\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, UIElement):\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_show_with_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbrowser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnotebook_handle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnotebook_handle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_application\u001b[39m(obj: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TypeGuard[Application]:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_is_a_bokeh_application_class\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/io/showing.py:196\u001b[0m, in \u001b[0;36m_show_with_state\u001b[0;34m(obj, state, browser, new, notebook_handle)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39mnotebook:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m state\u001b[38;5;241m.\u001b[39mnotebook_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     comms_handle \u001b[38;5;241m=\u001b[39m \u001b[43mrun_notebook_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotebook_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdoc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnotebook_handle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     shown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39mfile \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m shown:\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/io/notebook.py:372\u001b[0m, in \u001b[0;36mrun_notebook_hook\u001b[0;34m(notebook_type, action, *args, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _HOOKS[notebook_type][action] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnotebook hook for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnotebook_type\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m did not install \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maction\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m action\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_HOOKS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnotebook_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/io/notebook.py:608\u001b[0m, in \u001b[0;36mshow_doc\u001b[0;34m(obj, state, notebook_handle)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m notebook_content\n\u001b[1;32m    607\u001b[0m comms_target \u001b[38;5;241m=\u001b[39m make_id() \u001b[38;5;28;01mif\u001b[39;00m notebook_handle \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m (script, div, cell_doc) \u001b[38;5;241m=\u001b[39m \u001b[43mnotebook_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomms_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m publish_display_data({HTML_MIME_TYPE: div})\n\u001b[1;32m    611\u001b[0m publish_display_data({JS_MIME_TYPE: script, EXEC_MIME_TYPE: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m}, metadata\u001b[38;5;241m=\u001b[39m{EXEC_MIME_TYPE: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: obj\u001b[38;5;241m.\u001b[39mid}})\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/embed/notebook.py:90\u001b[0m, in \u001b[0;36mnotebook_content\u001b[0;34m(model, notebook_comms_target, theme)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Comms handling relies on the fact that the new_doc returned here\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# has models with the same IDs as they were started with\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OutputDocumentFor([model], apply_theme\u001b[38;5;241m=\u001b[39mtheme, always_new\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m new_doc:\n\u001b[0;32m---> 90\u001b[0m     (docs_json, [render_item]) \u001b[38;5;241m=\u001b[39m \u001b[43mstandalone_docs_json_and_render_items\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m div \u001b[38;5;241m=\u001b[39m div_for_render_item(render_item)\n\u001b[1;32m     94\u001b[0m render_item \u001b[38;5;241m=\u001b[39m render_item\u001b[38;5;241m.\u001b[39mto_json()\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/embed/util.py:333\u001b[0m, in \u001b[0;36mstandalone_docs_json_and_render_items\u001b[0;34m(models, suppress_callback_warning)\u001b[0m\n\u001b[1;32m    331\u001b[0m docs_json: \u001b[38;5;28mdict\u001b[39m[ID, DocJson] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc, (docid, _) \u001b[38;5;129;01min\u001b[39;00m docs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 333\u001b[0m     docs_json[docid] \u001b[38;5;241m=\u001b[39m \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeferred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m render_items: \u001b[38;5;28mlist\u001b[39m[RenderItem] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, (docid, roots) \u001b[38;5;129;01min\u001b[39;00m docs\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/document/document.py:752\u001b[0m, in \u001b[0;36mDocument.to_json\u001b[0;34m(self, deferred)\u001b[0m\n\u001b[1;32m    750\u001b[0m serializer \u001b[38;5;241m=\u001b[39m Serializer(deferred\u001b[38;5;241m=\u001b[39mdeferred)\n\u001b[1;32m    751\u001b[0m defs \u001b[38;5;241m=\u001b[39m serializer\u001b[38;5;241m.\u001b[39mencode(data_models)\n\u001b[0;32m--> 752\u001b[0m roots \u001b[38;5;241m=\u001b[39m \u001b[43mserializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_roots\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    753\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m serializer\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39m_js_event_callbacks)\n\u001b[1;32m    755\u001b[0m doc_json \u001b[38;5;241m=\u001b[39m DocJson(\n\u001b[1;32m    756\u001b[0m     version\u001b[38;5;241m=\u001b[39m__version__,\n\u001b[1;32m    757\u001b[0m     title\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtitle,\n\u001b[1;32m    758\u001b[0m     roots\u001b[38;5;241m=\u001b[39mroots,\n\u001b[1;32m    759\u001b[0m )\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:253\u001b[0m, in \u001b[0;36mSerializer.encode\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_circular[ident] \u001b[38;5;241m=\u001b[39m obj\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_circular[ident]\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:278\u001b[0m, in \u001b[0;36mSerializer._encode\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_tuple(obj)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m--> 278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mset\u001b[39m):\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_set(obj)\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:326\u001b[0m, in \u001b[0;36mSerializer._encode_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode_list\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: \u001b[38;5;28mlist\u001b[39m[Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayRepLike:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(item) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m obj]\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:326\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode_list\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: \u001b[38;5;28mlist\u001b[39m[Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayRepLike:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m obj]\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:253\u001b[0m, in \u001b[0;36mSerializer.encode\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_circular[ident] \u001b[38;5;241m=\u001b[39m obj\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_circular[ident]\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:262\u001b[0m, in \u001b[0;36mSerializer._encode\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AnyRep:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, Serializable):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_serializable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (encoder \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encoders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mtype\u001b[39m(obj))) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encoder(obj, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/model/model.py:534\u001b[0m, in \u001b[0;36mModel.to_serializable\u001b[0;34m(self, serializer)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_serializable\u001b[39m(\u001b[38;5;28mself\u001b[39m, serializer: Serializer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ObjectRefRep:\n\u001b[1;32m    532\u001b[0m     serializer\u001b[38;5;241m.\u001b[39madd_ref(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mref)\n\u001b[0;32m--> 534\u001b[0m     super_rep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_serializable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserializer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m     rep \u001b[38;5;241m=\u001b[39m ObjectRefRep(\n\u001b[1;32m    536\u001b[0m         \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    537\u001b[0m         name\u001b[38;5;241m=\u001b[39msuper_rep[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m    539\u001b[0m     )\n\u001b[1;32m    541\u001b[0m     attributes \u001b[38;5;241m=\u001b[39m super_rep\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattributes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/has_props.py:417\u001b[0m, in \u001b[0;36mHasProps.to_serializable\u001b[0;34m(self, serializer)\u001b[0m\n\u001b[1;32m    411\u001b[0m rep \u001b[38;5;241m=\u001b[39m ObjectRep(\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    413\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__qualified_model__,\n\u001b[1;32m    414\u001b[0m )\n\u001b[1;32m    416\u001b[0m properties \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproperties_with_values(include_defaults\u001b[38;5;241m=\u001b[39msettings\u001b[38;5;241m.\u001b[39mserialize_include_defaults())\n\u001b[0;32m--> 417\u001b[0m attributes \u001b[38;5;241m=\u001b[39m {key: serializer\u001b[38;5;241m.\u001b[39mencode(val) \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m properties\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attributes:\n\u001b[1;32m    420\u001b[0m     rep[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattributes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m attributes\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/has_props.py:417\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    411\u001b[0m rep \u001b[38;5;241m=\u001b[39m ObjectRep(\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    413\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__qualified_model__,\n\u001b[1;32m    414\u001b[0m )\n\u001b[1;32m    416\u001b[0m properties \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproperties_with_values(include_defaults\u001b[38;5;241m=\u001b[39msettings\u001b[38;5;241m.\u001b[39mserialize_include_defaults())\n\u001b[0;32m--> 417\u001b[0m attributes \u001b[38;5;241m=\u001b[39m {key: \u001b[43mserializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m properties\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attributes:\n\u001b[1;32m    420\u001b[0m     rep[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattributes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m attributes\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:253\u001b[0m, in \u001b[0;36mSerializer.encode\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_circular[ident] \u001b[38;5;241m=\u001b[39m obj\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_circular[ident]\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:278\u001b[0m, in \u001b[0;36mSerializer._encode\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_tuple(obj)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m--> 278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mset\u001b[39m):\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_set(obj)\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:326\u001b[0m, in \u001b[0;36mSerializer._encode_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode_list\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: \u001b[38;5;28mlist\u001b[39m[Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayRepLike:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(item) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m obj]\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:326\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode_list\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: \u001b[38;5;28mlist\u001b[39m[Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayRepLike:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m obj]\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:253\u001b[0m, in \u001b[0;36mSerializer.encode\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_circular[ident] \u001b[38;5;241m=\u001b[39m obj\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_circular[ident]\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:262\u001b[0m, in \u001b[0;36mSerializer._encode\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AnyRep:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, Serializable):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_serializable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (encoder \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encoders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mtype\u001b[39m(obj))) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encoder(obj, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/model/model.py:534\u001b[0m, in \u001b[0;36mModel.to_serializable\u001b[0;34m(self, serializer)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_serializable\u001b[39m(\u001b[38;5;28mself\u001b[39m, serializer: Serializer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ObjectRefRep:\n\u001b[1;32m    532\u001b[0m     serializer\u001b[38;5;241m.\u001b[39madd_ref(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mref)\n\u001b[0;32m--> 534\u001b[0m     super_rep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_serializable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserializer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m     rep \u001b[38;5;241m=\u001b[39m ObjectRefRep(\n\u001b[1;32m    536\u001b[0m         \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    537\u001b[0m         name\u001b[38;5;241m=\u001b[39msuper_rep[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m    539\u001b[0m     )\n\u001b[1;32m    541\u001b[0m     attributes \u001b[38;5;241m=\u001b[39m super_rep\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattributes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/has_props.py:417\u001b[0m, in \u001b[0;36mHasProps.to_serializable\u001b[0;34m(self, serializer)\u001b[0m\n\u001b[1;32m    411\u001b[0m rep \u001b[38;5;241m=\u001b[39m ObjectRep(\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    413\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__qualified_model__,\n\u001b[1;32m    414\u001b[0m )\n\u001b[1;32m    416\u001b[0m properties \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproperties_with_values(include_defaults\u001b[38;5;241m=\u001b[39msettings\u001b[38;5;241m.\u001b[39mserialize_include_defaults())\n\u001b[0;32m--> 417\u001b[0m attributes \u001b[38;5;241m=\u001b[39m {key: serializer\u001b[38;5;241m.\u001b[39mencode(val) \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m properties\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attributes:\n\u001b[1;32m    420\u001b[0m     rep[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattributes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m attributes\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/has_props.py:417\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    411\u001b[0m rep \u001b[38;5;241m=\u001b[39m ObjectRep(\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    413\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__qualified_model__,\n\u001b[1;32m    414\u001b[0m )\n\u001b[1;32m    416\u001b[0m properties \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproperties_with_values(include_defaults\u001b[38;5;241m=\u001b[39msettings\u001b[38;5;241m.\u001b[39mserialize_include_defaults())\n\u001b[0;32m--> 417\u001b[0m attributes \u001b[38;5;241m=\u001b[39m {key: \u001b[43mserializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m properties\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attributes:\n\u001b[1;32m    420\u001b[0m     rep[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattributes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m attributes\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:253\u001b[0m, in \u001b[0;36mSerializer.encode\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_circular[ident] \u001b[38;5;241m=\u001b[39m obj\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_circular[ident]\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:278\u001b[0m, in \u001b[0;36mSerializer._encode\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_tuple(obj)\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m--> 278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mset\u001b[39m):\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_set(obj)\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:326\u001b[0m, in \u001b[0;36mSerializer._encode_list\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode_list\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: \u001b[38;5;28mlist\u001b[39m[Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayRepLike:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(item) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m obj]\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:326\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode_list\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: \u001b[38;5;28mlist\u001b[39m[Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayRepLike:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m obj]\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:253\u001b[0m, in \u001b[0;36mSerializer.encode\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_circular[ident] \u001b[38;5;241m=\u001b[39m obj\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_circular[ident]\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:262\u001b[0m, in \u001b[0;36mSerializer._encode\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AnyRep:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, Serializable):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_serializable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (encoder \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encoders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mtype\u001b[39m(obj))) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encoder(obj, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/model/model.py:534\u001b[0m, in \u001b[0;36mModel.to_serializable\u001b[0;34m(self, serializer)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_serializable\u001b[39m(\u001b[38;5;28mself\u001b[39m, serializer: Serializer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ObjectRefRep:\n\u001b[1;32m    532\u001b[0m     serializer\u001b[38;5;241m.\u001b[39madd_ref(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mref)\n\u001b[0;32m--> 534\u001b[0m     super_rep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_serializable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserializer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m     rep \u001b[38;5;241m=\u001b[39m ObjectRefRep(\n\u001b[1;32m    536\u001b[0m         \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    537\u001b[0m         name\u001b[38;5;241m=\u001b[39msuper_rep[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m    539\u001b[0m     )\n\u001b[1;32m    541\u001b[0m     attributes \u001b[38;5;241m=\u001b[39m super_rep\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattributes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/has_props.py:417\u001b[0m, in \u001b[0;36mHasProps.to_serializable\u001b[0;34m(self, serializer)\u001b[0m\n\u001b[1;32m    411\u001b[0m rep \u001b[38;5;241m=\u001b[39m ObjectRep(\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    413\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__qualified_model__,\n\u001b[1;32m    414\u001b[0m )\n\u001b[1;32m    416\u001b[0m properties \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproperties_with_values(include_defaults\u001b[38;5;241m=\u001b[39msettings\u001b[38;5;241m.\u001b[39mserialize_include_defaults())\n\u001b[0;32m--> 417\u001b[0m attributes \u001b[38;5;241m=\u001b[39m {key: serializer\u001b[38;5;241m.\u001b[39mencode(val) \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m properties\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attributes:\n\u001b[1;32m    420\u001b[0m     rep[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattributes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m attributes\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/has_props.py:417\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    411\u001b[0m rep \u001b[38;5;241m=\u001b[39m ObjectRep(\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    413\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__qualified_model__,\n\u001b[1;32m    414\u001b[0m )\n\u001b[1;32m    416\u001b[0m properties \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproperties_with_values(include_defaults\u001b[38;5;241m=\u001b[39msettings\u001b[38;5;241m.\u001b[39mserialize_include_defaults())\n\u001b[0;32m--> 417\u001b[0m attributes \u001b[38;5;241m=\u001b[39m {key: \u001b[43mserializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m properties\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attributes:\n\u001b[1;32m    420\u001b[0m     rep[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattributes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m attributes\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:253\u001b[0m, in \u001b[0;36mSerializer.encode\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_circular[ident] \u001b[38;5;241m=\u001b[39m obj\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_circular[ident]\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:262\u001b[0m, in \u001b[0;36mSerializer._encode\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AnyRep:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, Serializable):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_serializable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (encoder \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encoders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mtype\u001b[39m(obj))) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    264\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encoder(obj, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/model/model.py:534\u001b[0m, in \u001b[0;36mModel.to_serializable\u001b[0;34m(self, serializer)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_serializable\u001b[39m(\u001b[38;5;28mself\u001b[39m, serializer: Serializer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ObjectRefRep:\n\u001b[1;32m    532\u001b[0m     serializer\u001b[38;5;241m.\u001b[39madd_ref(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mref)\n\u001b[0;32m--> 534\u001b[0m     super_rep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_serializable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserializer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m     rep \u001b[38;5;241m=\u001b[39m ObjectRefRep(\n\u001b[1;32m    536\u001b[0m         \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    537\u001b[0m         name\u001b[38;5;241m=\u001b[39msuper_rep[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m    539\u001b[0m     )\n\u001b[1;32m    541\u001b[0m     attributes \u001b[38;5;241m=\u001b[39m super_rep\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattributes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/has_props.py:417\u001b[0m, in \u001b[0;36mHasProps.to_serializable\u001b[0;34m(self, serializer)\u001b[0m\n\u001b[1;32m    411\u001b[0m rep \u001b[38;5;241m=\u001b[39m ObjectRep(\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    413\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__qualified_model__,\n\u001b[1;32m    414\u001b[0m )\n\u001b[1;32m    416\u001b[0m properties \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproperties_with_values(include_defaults\u001b[38;5;241m=\u001b[39msettings\u001b[38;5;241m.\u001b[39mserialize_include_defaults())\n\u001b[0;32m--> 417\u001b[0m attributes \u001b[38;5;241m=\u001b[39m {key: serializer\u001b[38;5;241m.\u001b[39mencode(val) \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m properties\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attributes:\n\u001b[1;32m    420\u001b[0m     rep[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattributes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m attributes\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/has_props.py:417\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    411\u001b[0m rep \u001b[38;5;241m=\u001b[39m ObjectRep(\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    413\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__qualified_model__,\n\u001b[1;32m    414\u001b[0m )\n\u001b[1;32m    416\u001b[0m properties \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproperties_with_values(include_defaults\u001b[38;5;241m=\u001b[39msettings\u001b[38;5;241m.\u001b[39mserialize_include_defaults())\n\u001b[0;32m--> 417\u001b[0m attributes \u001b[38;5;241m=\u001b[39m {key: \u001b[43mserializer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m properties\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attributes:\n\u001b[1;32m    420\u001b[0m     rep[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattributes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m attributes\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:253\u001b[0m, in \u001b[0;36mSerializer.encode\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_circular[ident] \u001b[38;5;241m=\u001b[39m obj\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_circular[ident]\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:282\u001b[0m, in \u001b[0;36mSerializer._encode\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_set(obj)\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, SimpleNamespace):\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_struct(obj)\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:343\u001b[0m, in \u001b[0;36mSerializer._encode_dict\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m     result \u001b[38;5;241m=\u001b[39m MapRep(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    341\u001b[0m     result \u001b[38;5;241m=\u001b[39m MapRep(\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 343\u001b[0m         entries\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(key), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(val)) \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems()],\n\u001b[1;32m    344\u001b[0m     )\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:343\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    339\u001b[0m     result \u001b[38;5;241m=\u001b[39m MapRep(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    341\u001b[0m     result \u001b[38;5;241m=\u001b[39m MapRep(\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 343\u001b[0m         entries\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(key), \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mitems()],\n\u001b[1;32m    344\u001b[0m     )\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:253\u001b[0m, in \u001b[0;36mSerializer.encode\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_circular[ident] \u001b[38;5;241m=\u001b[39m obj\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_circular[ident]\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:299\u001b[0m, in \u001b[0;36mSerializer._encode\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_dataclass(obj)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_other\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:477\u001b[0m, in \u001b[0;36mSerializer._encode_other\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__array__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr \u001b[38;5;241m:=\u001b[39m obj\u001b[38;5;241m.\u001b[39m__array__(), np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_ndarray(arr)\n\u001b[0;32m--> 477\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcan\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt serialize \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/pinn-for-physiological-timeseries-main/.venv/lib/python3.9/site-packages/bokeh/core/serialization.py:480\u001b[0m, in \u001b[0;36mSerializer.error\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror\u001b[39m(\u001b[38;5;28mself\u001b[39m, message: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m--> 480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SerializationError(message)\n",
      "\u001b[0;31mSerializationError\u001b[0m: can't serialize <class 'range'>"
     ]
    }
   ],
   "source": [
    "s=figure(width=770,height=400,y_range=(out_min_rescaled-20,out_max_rescaled+20))\n",
    "s.scatter(ix_test,np.concatenate(scaler_out.inverse_transform(np.concatenate(model_dnn_conv(inp_comb_test))[:,None])),size=7,line_color=None,color=palettes.Colorblind8[5],legend_label='Conv.')\n",
    "s.scatter(ix_test,np.concatenate(scaler_out.inverse_transform(np.concatenate(model_dnn_pinn(inp_comb_test))[:,None])),size=7,line_color=None,color=palettes.Colorblind8[3],legend_label='PINN')\n",
    "s.line(range(len(df_demo_data)),np.concatenate(scaler_out.inverse_transform(all_out[:,0][:,None])),line_width=3,line_color='black',line_alpha=1,line_dash='dashed',legend_label='True BP')\n",
    "s.xaxis.axis_label='Beat time (s)'\n",
    "s.yaxis.axis_label='SBP (mmHg)'\n",
    "\n",
    "s2 = figure(width=500,height=400,y_axis_type=\"log\",y_range=(1e-2,2))\n",
    "#s2.line(np.linspace(0,100,len(loss_list_conv)),loss_list_conv,line_width=3,color='black',legend_label='PINN-test')\n",
    "#s2.line(np.linspace(0,100,len(test_loss_list_conv)),test_loss_list_conv,line_width=3,line_dash='dashed',color='black',legend_label='Conv-test')\n",
    "#s2.line(np.linspace(0,100,len(loss_list_pinn)),loss_list_pinn,line_width=3,alpha=0.8,color='orange',legend_label='PINN-train')\n",
    "#s2.line(np.linspace(0,100,len(test_loss_list_pinn)),test_loss_list_pinn,line_width=3,line_dash='dashed',color='orange',legend_label='Conv-train')\n",
    "# 假设您想要展示的训练百分比范围是从0到100，总共有len(loss_list_conv)个点\n",
    "\n",
    "# Convert range object to list\n",
    "x_range = list(range(len(loss_list_conv)))\n",
    "\n",
    "# 更新图表绘制代码\n",
    "s2.line(x_range, loss_list_conv, line_width=3, color='black', legend_label='PINN-test')\n",
    "s2.line(x_range, test_loss_list_conv, line_width=3, line_dash='dashed', color='black', legend_label='Conv-test')\n",
    "s2.line(x_range, loss_list_pinn, line_width=3, alpha=0.8, color='orange', legend_label='PINN-train')\n",
    "s2.line(x_range, test_loss_list_pinn, line_width=3, line_dash='dashed', color='orange', legend_label='Conv-train')\n",
    "\n",
    "s2.xaxis.axis_label = 'Training percent (%)'\n",
    "s2.yaxis.axis_label = 'mse norm.'\n",
    "\n",
    "figure_settings(s)\n",
    "figure_settings(s2)\n",
    "\n",
    "show(row(s,s2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1776ae4-7d3a-4ccf-837d-4ccac58e89fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Row' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43ms2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m (plot)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;28mtype\u001b[39m(plot))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Row' object is not iterable"
     ]
    }
   ],
   "source": [
    "plot = list(row(s,s2))\n",
    "print (plot)\n",
    "print (type(plot))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3587427c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
